{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "Lung Cancer Segmentation- NSCLS-Radiomics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1r2zHYMTvLq",
        "colab_type": "text"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkZlq4zV9eIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Specify if you want to enable the test code. \n",
        "#When you run entire notebook, set it to false.\n",
        "global_is_test = true"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q09A3m7wpyBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mount google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "#install required packages\n",
        "!pip3 install pydicom\n",
        "!pip3 install dicom_contour\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD7iwubKR-jE",
        "colab_type": "text"
      },
      "source": [
        "# Get data files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ius5TFZxSWJk",
        "colab_type": "text"
      },
      "source": [
        "## Copy files from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZniN5zvSVSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#unzip the data fromthe google drive to the VM\n",
        "!unzip '/gdrive/My Drive/Lung/lung-full.zip' -d  '/content/lung/'\n",
        "\n",
        "#!unzip '/gdrive/My Drive/Lung/lung.zip' -d  '/content/lung/'\n",
        "#!unzip '/gdrive/My Drive/Lung/lung-test.zip' -d  '/content/lung/lung-test/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdopMLpoR3Gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Delete bad data sets\n",
        "#!rm -rf '/content/lung/LUNG1-095'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTzVETWMpjZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pydicom\n",
        "import numpy as np\n",
        "import dicom_contour.contour as dcm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "slices_imgpath_dict = {}\n",
        "slice_orders = []\n",
        "#from dicom_contour import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhB0aFn9T0Qh",
        "colab_type": "text"
      },
      "source": [
        "# Define required methods"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SrOOz0Dc1BJ",
        "colab_type": "text"
      },
      "source": [
        "##Convert Hounsfield Unit to Pixels \n",
        "The unit of measurement in CT scans is the **Hounsfield Unit (HU)**, which is a measure of radiodensity. CT scanners are carefully calibrated to accurately measure this.  From Wikipedia:\n",
        "\n",
        "![HU examples][1]\n",
        "\n",
        "By default however, the returned values are not in this unit. Let's fix this.\n",
        "\n",
        "Some scanners have cylindrical scanning bounds, but the output image is square. The pixels that fall outside of these bounds get the fixed value -2000. The first step is setting these values to 0, which currently corresponds to air. Next, let's go back to HU units, by multiplying with the rescale slope and adding the intercept (which are conveniently stored in the metadata of the scans!).\n",
        "\n",
        "  [1]: http://i.imgur.com/4rlyReh.png"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boJunPqApjZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This method returns the image in the HU Units\n",
        "def parse_dicom_file(fileName):\n",
        "  \"\"\"Parse the given DICOM filename\n",
        "    :param filename: filepath to the DICOM file to parse\n",
        "    :return: dictionary with DICOM image data\n",
        "    \"\"\"\n",
        "  try:\n",
        "    dcm = pydicom.read_file(fileName)\n",
        "    dcm_image = dcm.pixel_array\n",
        "\n",
        "    # Convert to int16 (from sometimes int16), \n",
        "    # should be possible as values should always be low enough (<32k)\n",
        "    dcm_image = dcm_image.astype(np.int16)\n",
        "\n",
        "    # Set outside-of-scan pixels to 0\n",
        "    # The intercept is usually -1024, so air is approximately 0\n",
        "    dcm_image[dcm_image == -2000] = 0\n",
        "\n",
        "    try:\n",
        "        intercept = dcm.RescaleIntercept        \n",
        "    except AttributeError:        \n",
        "        intercept = 0.0\n",
        "\n",
        "    try:\n",
        "        slope = dcm.RescaleSlope        \n",
        "    except AttributeError:        \n",
        "        slope = 0.0\n",
        "    \n",
        "    if slope != 1:\n",
        "      dcm_image = slope * dcm_image.astype(np.float64)\n",
        "      dcm_image = dcm_image.astype(np.int16)            \n",
        "      dcm_image += np.int16(intercept)\n",
        "\n",
        "    return np.array(dcm_image, dtype=np.int16)\n",
        "\n",
        "  except:\n",
        "    return None\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2fRL-RypjZV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_roi_contour_ds(rt_sequence, index):\n",
        "    \"\"\"\n",
        "    Extract desired Regions of Interest(ROI) contour datasets\n",
        "    from RT Sequence.\n",
        "    \n",
        "    E.g. rt_sequence can have contours for different parts of the lung\n",
        "    \n",
        "    You can use get_roi_names to find which index to use\n",
        "    \n",
        "    Inputs:\n",
        "        rt_sequence (pydicom.dataset.FileDataset): Contour file dataset, what you get \n",
        "                                                after reading contour DICOM file\n",
        "        index (int): Index for ROI Sequence\n",
        "    Return:\n",
        "        contours (list): list of ROI contour pydicom.dataset.Dataset s\n",
        "    \"\"\"\n",
        "    if (len(rt_sequence.ROIContourSequence) == 0):\n",
        "      return []\n",
        "\n",
        "    # index 0 means that we are getting RTV information\n",
        "    ROI = rt_sequence.ROIContourSequence[index]\n",
        "    # get contour datasets in a list\n",
        "    contours = [contour for contour in ROI.ContourSequence]\n",
        "    return contours\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mseb2BupjZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def contour2poly(contour_dataset, path,slices_imgpath_dict):\n",
        "    \"\"\"\n",
        "    Given a contour dataset (a DICOM class) and path that has .dcm files of\n",
        "    corresponding images return polygon coordinates for the contours.\n",
        "\n",
        "    Inputs\n",
        "        contour_dataset (pydicom.dataset.Dataset) : DICOM dataset class that is identified as\n",
        "                        (3006, 0016)  Contour Image Sequence\n",
        "        path (str): path of directory containing DICOM images\n",
        "\n",
        "    Return:\n",
        "        pixel_coords (list): list of tuples having pixel coordinates\n",
        "        img_ID (id): DICOM image id which maps input contour dataset\n",
        "        img_shape (tuple): DICOM image shape - height, width\n",
        "    \"\"\"\n",
        "\n",
        "    contour_coord = contour_dataset.ContourData\n",
        "    # x, y, z coordinates of the contour in mm\n",
        "    \n",
        "    coord = []\n",
        "    for i in range(0, len(contour_coord), 3):\n",
        "        coord.append((contour_coord[i], contour_coord[i + 1], contour_coord[i + 2]))\n",
        "\n",
        "    # extract the image id corresponding to given countour\n",
        "    # read that dicom file\n",
        "    img_ID = contour_dataset.ContourImageSequence[0].ReferencedSOPInstanceUID\n",
        "    \n",
        "    if (img_ID not in slices_imgpath_dict):\n",
        "      print(\"Image ID:\", img_ID, \"not found in the slice image path dict.\")\n",
        "      return;\n",
        "    \n",
        "    img = pydicom.read_file(os.path.join(path, slices_imgpath_dict[img_ID]))\n",
        "    img_arr = img.pixel_array\n",
        "    img_shape = img_arr.shape\n",
        "    \n",
        "    # physical distance between the center of each pixel\n",
        "    x_spacing, y_spacing = float(img.PixelSpacing[0]), float(img.PixelSpacing[1])\n",
        "\n",
        "    # this is the center of the upper left voxel\n",
        "    origin_x, origin_y, _ = img.ImagePositionPatient\n",
        "\n",
        "    # y, x is how it's mapped\n",
        "    pixel_coords = [(np.ceil((x - origin_x) / x_spacing), np.ceil((y - origin_y) / y_spacing))  for x, y, _ in coord]\n",
        "    return pixel_coords, img_ID, img_shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp_u6jexpjZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def poly_to_mask(polygon, width, height):\n",
        "    from PIL import Image, ImageDraw\n",
        "    \n",
        "    \"\"\"Convert polygon to mask\n",
        "    :param polygon: list of pairs of x, y coords [(x1, y1), (x2, y2), ...]\n",
        "    in units of pixels\n",
        "    :param width: scalar image width\n",
        "    :param height: scalar image height\n",
        "    :return: Boolean mask of shape (height, width)\n",
        "    \"\"\"\n",
        "\n",
        "    # http://stackoverflow.com/a/3732128/1410871\n",
        "    img = Image.new(mode='L', size=(width, height), color=0)\n",
        "    ImageDraw.Draw(img).polygon(xy=polygon, outline=0, fill=1)\n",
        "    mask = np.array(img).astype(bool)\n",
        "    return mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9U6CnGLpjZd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_mask_dict(contour_datasets, path, slices_imgpath_dict):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "        contour_datasets (list): list of pydicom.dataset.Dataset for contours\n",
        "        path (str): path of directory with images\n",
        "\n",
        "    Return:\n",
        "        img_contours_dict (dict): img_id : contour array pairs\n",
        "    \"\"\"\n",
        "    \n",
        "    from collections import defaultdict\n",
        "    \n",
        "    # create empty dict for \n",
        "    img_contours_dict = defaultdict(int)\n",
        "\n",
        "    for cdataset in contour_datasets:\n",
        "        coords, img_id, shape = contour2poly(cdataset, path, slices_imgpath_dict) or (None, None, None)\n",
        "        if coords is None:\n",
        "          continue\n",
        "          \n",
        "        mask = poly_to_mask(coords, *shape)\n",
        "        img_contours_dict[img_id] += mask\n",
        "    \n",
        "    return img_contours_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG6J8As0pjZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_img_mask_voxel(slice_orders, mask_dict, image_path, slices_imgpath_dict):\n",
        "    \"\"\" \n",
        "    Construct image and mask voxels\n",
        "    \n",
        "    Inputs:\n",
        "        slice_orders (list): list of tuples of ordered img_id and z-coordinate position\n",
        "        mask_dict (dict): dictionary having img_id : contour array pairs\n",
        "        image_path (str): directory path containing DICOM image files\n",
        "    Return: \n",
        "        img_voxel: ordered image voxel for CT/MR\n",
        "        mask_voxel: ordered mask voxel for CT/MR\n",
        "    \"\"\"\n",
        "    \n",
        "    img_voxel = []\n",
        "    mask_voxel = []\n",
        "    tumor_only_slices = []\n",
        "    for img_id, _ in slice_orders:\n",
        "        path = os.path.join(image_path, slices_imgpath_dict[img_id])\n",
        "        img_array = parse_dicom_file(path)\n",
        "        \n",
        "        if img_id in mask_dict: \n",
        "          mask_array = mask_dict[img_id]\n",
        "          if (np.count_nonzero(mask_array) > 0):\n",
        "            tumor_only_slices.append(1)\n",
        "          else:\n",
        "            tumor_only_slices.append(0)\n",
        "        else: \n",
        "          mask_array = np.zeros_like(img_array)\n",
        "          tumor_only_slices.append(0)\n",
        "          \n",
        "        img_voxel.append(img_array)\n",
        "        mask_voxel.append(mask_array)\n",
        "        \n",
        "    return img_voxel, mask_voxel, tumor_only_slices\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Vw4xsAKpjZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_img_msk_fromarray(img_arr, msk_arr, alpha=0.35, sz=7, cmap='inferno',\n",
        "                           save_path=None):\n",
        "\n",
        "    \"\"\"\n",
        "    Show original image and masked on top of image\n",
        "    next to each other in desired size\n",
        "    Inputs:\n",
        "        img_arr (np.array): array of the image\n",
        "        msk_arr (np.array): array of the mask\n",
        "        alpha (float): a number between 0 and 1 for mask transparency\n",
        "        sz (int): figure size for display\n",
        "        save_path (str): path to save the figure\n",
        "    \"\"\"\n",
        "\n",
        "    msk_arr = np.ma.masked_where(msk_arr == 0, msk_arr)\n",
        "    plt.figure(figsize=(sz, sz))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img_arr, cmap='gray')\n",
        "    plt.imshow(msk_arr, cmap=cmap, alpha=alpha)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(img_arr, cmap='gray')\n",
        "    if save_path is None:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.savefig(save_path)\n",
        "        plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssj84F1npjZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def slice_order(path):\n",
        "    \"\"\"\n",
        "    Takes path of directory that has the DICOM images and returns\n",
        "    a ordered list that has ordered filenames\n",
        "    Inputs\n",
        "        path: path that has .dcm images\n",
        "    Returns\n",
        "        ordered_slices: ordered tuples of filename and z-position\n",
        "    \"\"\"\n",
        "    # handle `/` missing\n",
        "    if path[-1] != '/': path += '/'\n",
        "    slices = []\n",
        "    slices_img_path = {}\n",
        "    for s in os.listdir(path):\n",
        "        try:\n",
        "            f = pydicom.read_file(path + '/' + s)\n",
        "            f.pixel_array  # to ensure not to read contour file\n",
        "            slices.append(f)\n",
        "            slices_img_path[f.SOPInstanceUID] = s\n",
        "        except:\n",
        "            continue\n",
        "\n",
        "    slice_dict = {s.SOPInstanceUID: s.ImagePositionPatient[-1] for s in slices}\n",
        "    ordered_slices = sorted(slice_dict.items(), key=dcm.operator.itemgetter(1))\n",
        "    return ordered_slices,slices_img_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwsVoC84pjZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_img(im, figsize=None, ax=None):\n",
        "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
        "    ax.imshow(im)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    return ax\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCzur2MEyDoe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tumor_slices(image_path, contour_filename, num_slices = 10):\n",
        "  # read dataset for contour\n",
        "  rt_sequence = pydicom.read_file(contour_filename)\n",
        "\n",
        "  # get contour datasets with index idx\n",
        "  idx = 0\n",
        "  contour_datasets = get_roi_contour_ds(rt_sequence, idx)\n",
        "\n",
        "  # get slice orders\n",
        "  slice_orders, slices_imgpath_dict = slice_order(image_path)\n",
        "\n",
        "  # construct mask dictionary\n",
        "  mask_dict = get_mask_dict(contour_datasets, image_path, slices_imgpath_dict)\n",
        "\n",
        "  # get image and mask data for patient\n",
        "  img_data, mask_data, tumor_only_slices = get_img_mask_voxel(slice_orders, mask_dict, image_path, slices_imgpath_dict)\n",
        "  if (1 in tumor_only_slices):\n",
        "    idx = tumor_only_slices.index(1)  \n",
        "    ldx = max(idx for idx, val in enumerate(tumor_only_slices) if val == 1) \n",
        "  \n",
        "    #Find the middle slice\n",
        "    middle_slice = round(idx + (ldx - idx) / 2)  \n",
        "  else:\n",
        "    middle_slice =  int(len(tumor_only_slices)/2)\n",
        "\n",
        "  start_slice = round(middle_slice - num_slices/2)\n",
        "  end_slice = round(middle_slice + num_slices/2)\n",
        "  \n",
        "  # Make sure the number of slices matches the requested number.\n",
        "  if (end_slice - start_slice > num_slices):\n",
        "    --end_slice\n",
        "    \n",
        "  if (end_slice - start_slice < num_slices):\n",
        "    ++end_slice\n",
        "\n",
        "  return img_data[start_slice:end_slice], mask_data[start_slice:end_slice]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5YIQ_4IVBA7",
        "colab_type": "text"
      },
      "source": [
        "# Test Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjFb50rfYJtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if global_is_test:\n",
        "  image_path = '/content/lung/LUNG1-176/05-06-2007-StudyID-46137/0-91507'\n",
        "\n",
        "  contour_filename = '/content/lung/LUNG1-176/05-06-2007-StudyID-46137/0-30658/000000.dcm'\n",
        "\n",
        "  # get slice orders\n",
        "  slice_orders, slices_imgpath_dict = slice_order(image_path)\n",
        "  print(slices_imgpath_dict)\n",
        "  print(slice_orders)\n",
        "  img_data, mask_data = get_tumor_slices(scan_image_path, contour_file_name)\n",
        "\n",
        "  #img_data = np.array(img_data)\n",
        "  #mask_data = np.array(mask_data)\n",
        "\n",
        "  #print(img_data[5][250])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFq70Nf0pjZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if global_is_test:\n",
        "  #### Full pipeline for getting img - mask data for a patient\n",
        "  image_path = '/content/lung/LUNG1-121/06-30-2006-StudyID-05880/0-76030'\n",
        "\n",
        "  contour_filename = '/content/lung/LUNG1-121/06-30-2006-StudyID-05880/1-89998/000000.dcm'\n",
        "\n",
        "  # read dataset for contour\n",
        "  rt_sequence = pydicom.read_file(contour_filename)\n",
        "\n",
        "  #print(rt_sequence.ROIContourSequence)\n",
        "\n",
        "  # get contour datasets with index idx\n",
        "  idx = 0\n",
        "  contour_datasets = get_roi_contour_ds(rt_sequence, idx)\n",
        "\n",
        "  # get slice orders\n",
        "  slice_orders, slices_imgpath_dict = slice_order(image_path)\n",
        "\n",
        "  # construct mask dictionary\n",
        "  mask_dict = get_mask_dict(contour_datasets, image_path,slices_imgpath_dict)\n",
        "\n",
        "  # get image and mask data for patient\n",
        "  img_data, mask_data, tumor_only_slices = get_img_mask_voxel(slice_orders, mask_dict, image_path, slices_imgpath_dict)\n",
        "\n",
        "\n",
        "\n",
        "  #tumor_only_slices\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckFMhjmL3axk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if global_is_test:\n",
        "  print(tumor_only_slices)\n",
        "\n",
        "\n",
        "  idx = tumor_only_slices.index(1)\n",
        "  if (idx > 0):\n",
        "    ldx = max(idx for idx, val in enumerate(tumor_only_slices) if val == 1) \n",
        "\n",
        "  print('First Index:', idx)\n",
        "  print('Last Index:', ldx)\n",
        "\n",
        "  middle_slice = round(idx + (ldx - idx) / 2)\n",
        "\n",
        "  num_slices = 10\n",
        "  start_slice = round(middle_slice - num_slices/2)\n",
        "  end_slice = round(middle_slice + num_slices/2)\n",
        "  #slide_range = range[start_slice, end_slice]\n",
        "\n",
        "  start_slice\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw1IkFGKpjZy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if global_is_test:\n",
        "  tumor_slice_count = 0;\n",
        "\n",
        "\n",
        "  for i,cntr in enumerate(contours):\n",
        "    if (np.count_nonzero(cntr) > 0) :\n",
        "      tumor_slice_count += 1\n",
        "\n",
        "      plt.imshow(images[i], cmap=plt.cm.gray)\n",
        "\n",
        "      cntr = np.ma.masked_where(cntr == 0, cntr) #mask the zero values.\n",
        "      plt.imshow(cntr, cmap='jet', interpolation='none', alpha=None)\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "  print(\"Number of slices with Tumor: \", tumor_slice_count)\n",
        "  #filled_cntr = dcm.fill_contour(cntr)\n",
        "  #plt.imshow(filled_cntr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VWAiVc6ZtNW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if global_is_test:\n",
        "  import glob\n",
        "  import os\n",
        "  import numpy as np\n",
        "\n",
        "  INPUT_FOLDER = '/content/lung/'\n",
        "  study_folders = glob.glob(os.path.join(INPUT_FOLDER, \"*\", \"*\"))\n",
        "\n",
        "  #Split the studies into training dataset and test data sets. (90:10)\n",
        "  studies = np.array(study_folders)\n",
        "  np.random.shuffle(studies)\n",
        "  num_studies = len(studies)\n",
        "\n",
        "  train_study_folders, test_study_folders = studies[:(int(num_studies * 0.95))], studies[(int(num_studies * 0.95)):]\n",
        "\n",
        "  print(len(train_study_folders))\n",
        "  print(\"--------------------------TEST-----------------------\")\n",
        "  print(len(test_study_folders))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAAMTWjdVFIX",
        "colab_type": "text"
      },
      "source": [
        "# Get all study data and create Numpy array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pyMUQlgJ8XQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "INPUT_FOLDER = '/content/lung/'\n",
        "IMG_WIDTH = 512\n",
        "IMG_HEIGHT = 512\n",
        "IMG_CHANNELS = 1\n",
        "IMG_NUM_IMAGES_PER_STUDY = 10\n",
        "\n",
        "study_folders = glob.glob(os.path.join(INPUT_FOLDER, \"*\", \"*\"))\n",
        "\n",
        "#Split the studies into training dataset and test data sets. \n",
        "studies = np.array(study_folders)\n",
        "np.random.shuffle(studies)\n",
        "num_studies = len(studies)\n",
        "\n",
        "train_study_folders, test_study_folders = studies[:(int(num_studies * 0.95))], studies[(int(num_studies * 0.95)):]\n",
        "\n",
        "X_train=np.zeros((len(train_study_folders), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), np.int16)\n",
        "Y_train=np.zeros((len(train_study_folders), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), np.int8)\n",
        "\n",
        "for si, sf in enumerate(train_study_folders):\n",
        "  scan_folders = glob.glob(os.path.join(sf, \"*\"))\n",
        "  \n",
        "  if (len(scan_folders) == 2):\n",
        "    scan_image_path = ''\n",
        "    contour_file_name = ''\n",
        "    scan = os.listdir(scan_folders[0])[0]\n",
        "    file_name = os.path.join(scan_folders[0], scan)\n",
        "   \n",
        "    try:\n",
        "      dicom_file = pydicom.read_file(file_name)     \n",
        "      dicom_file.pixel_array\n",
        "      scan_image_path = scan_folders[0]\n",
        "      contour_file_name = os.path.join(scan_folders[1], os.listdir(scan_folders[1])[0])      \n",
        "    except:\n",
        "      #This is contour file.     \n",
        "      scan_image_path = scan_folders[1]     \n",
        "      contour_file_name = file_name     \n",
        "    \n",
        "    print('Processing Scan path: ', scan_image_path)       \n",
        "    img_data, mask_data = get_tumor_slices(scan_image_path, contour_file_name)\n",
        "    for i in range(0, len(img_data)):\n",
        "      X_train[si, :, :, 0] = img_data[i]\n",
        "      Y_train[si, :, :, 0] = mask_data[i]\n",
        "\n",
        "    #Get the mask and image data only for X number of slices that has the tumor\n",
        "    \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMQggmpWQpZR",
        "colab_type": "text"
      },
      "source": [
        "# Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6uEzJY9QtB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test=np.zeros((len(test_study_folders), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), np.int8)\n",
        "sizes_test = []\n",
        "for si, sf in enumerate(test_study_folders):\n",
        "  scan_folders = glob.glob(os.path.join(sf, \"*\"))\n",
        "  for scan_folder in scan_folders:\n",
        "    scans = glob.glob(os.path.join(scan_folder, \"*\"))\n",
        "    if (len(scans) > 10):\n",
        "      X_test = np.zeros((len(scans), IMG_HEIGHT, IMG_WIDTH, 1), np.int16)\n",
        "\n",
        "      for i, scan_file in enumerate(scans):\n",
        "        dcm_file = pydicom.read_file(scan_file)\n",
        "        X_test[i,:, :, 0] = dcm_file.pixel_array\n",
        "        sizes_test.append([IMG_HEIGHT, IMG_WIDTH])\n",
        "\n",
        "  break\n",
        "\n",
        "      \n",
        "X_test.shape\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSZGhJfeRcpj",
        "colab_type": "text"
      },
      "source": [
        "# Build and train our neural network\n",
        "Next we build our U-Net model, loosely based on [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/pdf/1505.04597.pdf) and very similar to [this repo](https://github.com/jocicmarko/ultrasound-nerve-segmentation) from the Kaggle Ultrasound Nerve Segmentation competition.\n",
        "\n",
        "![](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGhOQWmQRg9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import neccessary packages\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Dropout, Lambda\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "from keras.optimizers import *\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
        "seed = 42\n",
        "random.seed = seed\n",
        "np.random.seed = seed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFabo0ACR2dA",
        "colab_type": "text"
      },
      "source": [
        "# Create our Keras metric\n",
        "\n",
        "Now we try to define the *mean average precision at different intersection over union (IoU) thresholds* metric in Keras. TensorFlow has a mean IoU metric, but it doesn't have any native support for the mean over multiple thresholds, so I tried to implement this. **I'm by no means certain that this implementation is correct, though!** Any assistance in verifying this would be most welcome! \n",
        "\n",
        "*Update: This implementation is most definitely not correct due to the very large discrepancy between the results reported here and the LB results. It also seems to just increase over time no matter what when you train ... *"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftF-Y0X3R1k9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define IoU metric\n",
        "def mean_iou(y_true, y_pred):\n",
        "    prec = []\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        y_pred_ = tf.to_int32(y_pred > t)\n",
        "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
        "        K.get_session().run(tf.local_variables_initializer())\n",
        "        with tf.control_dependencies([up_opt]):\n",
        "            score = tf.identity(score)\n",
        "        prec.append(score)\n",
        "    return K.mean(K.stack(prec), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NY1rrZLUR-yX",
        "colab_type": "text"
      },
      "source": [
        "**Build UNET Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOpuQg48SZnW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build U-Net model\n",
        "def build_cnn_unet_model():\n",
        "  inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
        "  s = Lambda(lambda x: x / 255) (inputs)\n",
        "\n",
        "  c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (s)\n",
        "  c1 = Dropout(0.5) (c1)\n",
        "  c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c1)\n",
        "  p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "  c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p1)\n",
        "  c2 = Dropout(0.5) (c2)\n",
        "  c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c2)\n",
        "  p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "  c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p2)\n",
        "  c3 = Dropout(0.2) (c3)\n",
        "  c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c3)\n",
        "  p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "  c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p3)\n",
        "  c4 = Dropout(0.2) (c4)\n",
        "  c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c4)\n",
        "  p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "  c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p4)\n",
        "  c5 = Dropout(0.3) (c5)\n",
        "  c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c5)\n",
        "\n",
        "  u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "  u6 = concatenate([u6, c4])\n",
        "  c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u6)\n",
        "  c6 = Dropout(0.2) (c6)\n",
        "  c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c6)\n",
        "\n",
        "  u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "  u7 = concatenate([u7, c3])\n",
        "  c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u7)\n",
        "  c7 = Dropout(0.2) (c7)\n",
        "  c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c7)\n",
        "\n",
        "  u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "  u8 = concatenate([u8, c2])\n",
        "  c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u8)\n",
        "  c8 = Dropout(0.5) (c8)\n",
        "  c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c8)\n",
        "\n",
        "  u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "  u9 = concatenate([u9, c1], axis=3)\n",
        "  c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u9)\n",
        "  c9 = Dropout(0.5) (c9)\n",
        "  c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c9)\n",
        "\n",
        "  outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "  model = Model(inputs=[inputs], outputs=[outputs])\n",
        "  #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
        "  model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0htU5u3B7nZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#call the function.\n",
        "model = build_cnn_unet_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vymd_4LSkZ7",
        "colab_type": "text"
      },
      "source": [
        "**Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMLfNxBFSjbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fit model\n",
        "earlystopper = EarlyStopping(patience=5, verbose=1)\n",
        "checkpointer = ModelCheckpoint('model-lung-segmentation.h5', verbose=1, save_best_only=True)\n",
        "results = model.fit(X_train, Y_train, validation_split=0.2, batch_size=16, epochs=50, \n",
        "                    callbacks=[earlystopper, checkpointer], shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leMmGYCbSsQS",
        "colab_type": "text"
      },
      "source": [
        "# Make predictions\n",
        "\n",
        "Let's make predictions both on the test set, the val set and the train set (as a sanity check). Remember to load the best saved model if you've used early stopping and checkpointing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThK4Zt62SwOb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict on train, val and test\n",
        "model = load_model('model-lung-segmentation.h5', custom_objects={'mean_iou': mean_iou})\n",
        "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
        "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
        "preds_test = model.predict(X_test, verbose=1)\n",
        "\n",
        "# Threshold predictions\n",
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
        "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
        "\n",
        "# Create list of upsampled test masks\n",
        "preds_test_upsampled = []\n",
        "for i in range(len(preds_test)):\n",
        "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
        "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
        "                                       mode='constant', preserve_range=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez007tfUJxXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWCyf_itJRYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.nonzero(preds_test)\n",
        "\n",
        "\n",
        "tumor_slice_count = 0;\n",
        "\n",
        "\n",
        "for i,cntr in enumerate(preds_test):\n",
        "  if (np.count_nonzero(cntr) > 0) :\n",
        "    tumor_slice_count += 1   \n",
        "    print(cntr.shape)\n",
        "    cntr = cntr.transpose(2,0,1)\n",
        "    \n",
        "    plt.imshow(cntr[0], cmap=plt.cm.gray)   \n",
        "    plt.show()\n",
        "\n",
        "print(\"Number of slices with Tumor: \", tumor_slice_count)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xeSbwrezJeS1",
        "colab": {}
      },
      "source": [
        "# Perform a sanity check on some random training samples\n",
        "ix = random.randint(0, len(preds_train_t))\n",
        "imshow(X_train[ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(Y_train[ix]))\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_train_t[ix]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnDtWo5TS1O1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Perform a sanity check on some random validation samples\n",
        "ix = random.randint(0, len(preds_val_t))\n",
        "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
        "plt.show()\n",
        "imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.9):][ix]))\n",
        "plt.show()\n",
        "imshow(np.squeeze(preds_val_t[ix]))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}